# Fine-tuning GPT на ваших документах

Fine-tuning позволяет "обучить" GPT-4o-mini специально на ваших данных для более точных и релевантных ответов.

## Зачем это нужно?

- **Лучшее понимание контекста**: Модель запоминает стиль и термины из ваших документов
- **Более точные ответы**: Знает специфические факты и связи между документами
- **Меньше "галлюцинаций"**: Меньше выдумывает, больше опирается на реальные данные

## Как это работает?

1. **Подготовка данных**: Создаем обучающие примеры из ваших документов
2. **Загрузка в OpenAI**: Отправляем данные на серверы OpenAI
3. **Обучение модели**: OpenAI дообучает GPT-4o-mini на ваших данных (~10-30 минут)
4. **Использование**: Получаем ID новой модели, подставляем в код

## Шаг 1: Подготовка данных

```bash
# Генерируем обучающие примеры из базы
node scripts/prepare-finetuning-data.js
```

Это создаст файл `finetuning-data.jsonl` с примерами вида:
```json
{"messages":[{"role":"system","content":"Ты эксперт..."},{"role":"user","content":"О чем документ?"},{"role":"assistant","content":"Документ рассказывает о..."}]}
```

## Шаг 2: Загрузка в OpenAI

### Через веб-интерфейс (проще):
1. Откройте https://platform.openai.com/finetune
2. Нажмите "Create fine-tuning job"
3. Загрузите `finetuning-data.jsonl`
4. Выберите модель: `gpt-4o-mini-2024-07-18`
5. Запустите обучение

### Через API (для автоматизации):
```bash
# 1. Загрузить файл
curl https://api.openai.com/v1/files \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -F purpose="fine-tune" \
  -F file="@finetuning-data.jsonl"

# Сохраните file_id из ответа

# 2. Запустить обучение
curl https://api.openai.com/v1/fine_tuning/jobs \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "training_file": "file-abc123", 
    "model": "gpt-4o-mini-2024-07-18"
  }'
```

## Шаг 3: Ожидание

Обучение занимает **10-30 минут** в зависимости от размера данных.

Проверить статус:
```bash
curl https://api.openai.com/v1/fine_tuning/jobs \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

Когда статус станет `succeeded`, модель готова!

## Шаг 4: Использование обученной модели

Получите ID модели (вида `ft:gpt-4o-mini-2024-07-18:your-org:model-name:abc123`)

Обновите `app/api/chat/route.ts`:
```typescript
model: 'ft:gpt-4o-mini-2024-07-18:your-org:model-name:abc123', // Ваш fine-tuned model
```

**Готово!** Теперь чат использует модель, обученную на ваших документах.

## Стоимость

- **Обучение**: ~$0.0080 / 1K tokens (одноразово)
- **Использование**: ~$0.30 / 1M input tokens (такая же как обычный GPT-4o-mini)

Пример: обучение на 100 документах (~500K tokens) = **$4**

## Когда переобучать?

- Добавили много новых документов (50+)
- Изменилась тематика базы знаний
- Хотите улучшить качество ответов

## Ограничения

- Минимум **10 обучающих примеров** (рекомендуется 50+)
- Максимум обучающих данных: практически неограничен
- Fine-tuned модель не "знает" новые документы автоматически - нужно переобучать

## Альтернатива: Embeddings + RAG (текущий подход)

Сейчас система использует **RAG** (Retrieval-Augmented Generation):
- Находит релевантные чанки через embeddings
- Отправляет их как контекст в промпт
- GPT отвечает на основе контекста

**Плюсы RAG**:
- ✅ Не требует обучения
- ✅ Работает с любыми новыми документами сразу
- ✅ Дешевле (нет затрат на fine-tuning)

**Плюсы Fine-tuning**:
- ✅ Модель "запоминает" ваши данные
- ✅ Лучше понимает специфическую терминологию
- ✅ Может отвечать без контекста (знает факты из обучения)

**Лучшее решение**: Комбинировать! Fine-tuning + RAG = максимальное качество.
